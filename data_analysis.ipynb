{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"results_trec_covid.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Subset   nDCG@10       MAP       MRR\n",
      "0          0  0.242830  0.120394  0.453432\n",
      "1          1  0.265432  0.124798  0.470772\n",
      "2          2  0.266056  0.125051  0.489842\n",
      "3          3  0.249523  0.119131  0.475298\n",
      "4          4  0.269700  0.122864  0.507224\n",
      "...      ...       ...       ...       ...\n",
      "1018    1018  0.247282  0.119172  0.442737\n",
      "1019    1019  0.237910  0.118469  0.448955\n",
      "1020    1020  0.247793  0.119102  0.467599\n",
      "1021    1021  0.241111  0.119199  0.435077\n",
      "1022    1022  0.240623  0.118414  0.463519\n",
      "\n",
      "[1023 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the file\n",
    "with open(FILE_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Initialize a dictionary to store parsed data\n",
    "data = {\"Subset\": [], \"nDCG@10\": [], \"MAP\": [], \"MRR\": []}\n",
    "\n",
    "# Temporary variables\n",
    "subset = None\n",
    "\n",
    "# Iterate through lines to extract information\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Subset\"):\n",
    "        subset = int(re.search(r'\\d+', line).group())  # Extract subset number\n",
    "    elif line.startswith(\"nDCG@10\"):\n",
    "        ndcg = float(line.split(\":\")[1].strip())\n",
    "    elif line.startswith(\"MAP\"):\n",
    "        map_val = float(line.split(\":\")[1].strip())\n",
    "    elif line.startswith(\"MRR\"):\n",
    "        mrr = float(line.split(\":\")[1].strip())\n",
    "        # Append extracted values to dictionary\n",
    "        data[\"Subset\"].append(subset)\n",
    "        data[\"nDCG@10\"].append(ndcg)\n",
    "        data[\"MAP\"].append(map_val)\n",
    "        data[\"MRR\"].append(mrr)\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "paraphrases = [\n",
    "    \"Improve the search effectiveness by suggesting expansion terms for the query\",\n",
    "    \"Recommend expansion terms for the query to improve search results\",\n",
    "    \"Improve the search effectiveness by suggesting useful expansion terms for the query\",\n",
    "    \"Maximize search utility by suggesting relevant expansion phrases for the query\",\n",
    "    \"Enhance search efficiency by proposing valuable terms to expand the query\",\n",
    "    \"Elevate search performance by recommending relevant expansion phrases for the query\",\n",
    "    \"Boost the search accuracy by providing helpful expansion terms to enrich the query\",\n",
    "    \"Increase the search efficacy by offering beneficial expansion keywords for the query\",\n",
    "    \"Optimize search results by suggesting meaningful expansion terms to enhance the query\",\n",
    "    \"Enhance search outcomes by recommending beneficial expansion terms to supplement the query\"\n",
    "]\n",
    "all_paraphrase_subsets = [subset for L in range(1, len(paraphrases) + 1) for subset in itertools.combinations(paraphrases, L)]\n",
    "\n",
    "def subset_num_to_paraphrases(num):\n",
    "    return all_paraphrase_subsets[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest nDCG@10 score:\n",
      "\n",
      "     Subset   nDCG@10       MAP       MRR\n",
      "279     279  0.282856  0.121228  0.527583\n",
      "\n",
      "Subset:\n",
      "('Recommend expansion terms for the query to improve search results', 'Improve the search effectiveness by suggesting useful expansion terms for the query', 'Optimize search results by suggesting meaningful expansion terms to enhance the query', 'Enhance search outcomes by recommending beneficial expansion terms to supplement the query')\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by='nDCG@10', ascending=False)\n",
    "print('Highest nDCG@10 score:\\n')\n",
    "print(df_sorted.head(1))\n",
    "\n",
    "print('\\nSubset:')\n",
    "print(subset_num_to_paraphrases(int(df_sorted.iloc[0]['Subset'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest MAP score:\n",
      "\n",
      "   Subset   nDCG@10       MAP       MRR\n",
      "2       2  0.266056  0.125051  0.489842\n",
      "\n",
      "Subset:\n",
      "('Improve the search effectiveness by suggesting useful expansion terms for the query',)\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by='MAP', ascending=False)\n",
    "print('Highest MAP score:\\n')\n",
    "print(df_sorted.head(1))\n",
    "\n",
    "print('\\nSubset:')\n",
    "print(subset_num_to_paraphrases(int(df_sorted.iloc[0]['Subset'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest MRR score:\n",
      "\n",
      "     Subset   nDCG@10      MAP       MRR\n",
      "588     588  0.266185  0.12184  0.571897\n",
      "\n",
      "Subset:\n",
      "('Improve the search effectiveness by suggesting useful expansion terms for the query', 'Maximize search utility by suggesting relevant expansion phrases for the query', 'Enhance search efficiency by proposing valuable terms to expand the query', 'Increase the search efficacy by offering beneficial expansion keywords for the query', 'Optimize search results by suggesting meaningful expansion terms to enhance the query')\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by='MRR', ascending=False)\n",
    "print('Highest MRR score:\\n')\n",
    "print(df_sorted.head(1))\n",
    "\n",
    "print('\\nSubset:')\n",
    "print(subset_num_to_paraphrases(int(df_sorted.iloc[0]['Subset'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subset size   nDCG@10       MAP       MRR\n",
      "0            1  0.257778  0.122727  0.478550\n",
      "1            2  0.254407  0.120821  0.474098\n",
      "2            3  0.252986  0.120016  0.473713\n",
      "3            4  0.252247  0.119658  0.477231\n",
      "4            5  0.250234  0.119356  0.473783\n",
      "5            6  0.247159  0.119213  0.471845\n",
      "6            7  0.244789  0.119017  0.463980\n",
      "7            8  0.244294  0.118856  0.459407\n",
      "8            9  0.242155  0.118635  0.452462\n",
      "9           10  0.240623  0.118414  0.463519\n"
     ]
    }
   ],
   "source": [
    "# Avg per subset size\n",
    "\n",
    "def filter_condition(subset_num, subset_size):\n",
    "    return len(subset_num_to_paraphrases(subset_num)) == subset_size\n",
    "\n",
    "all_averages = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    averages = {}\n",
    "    averages[\"Subset size\"] = i\n",
    "    filtered_df = df[df[\"Subset\"].apply(lambda x: filter_condition(x, i))]\n",
    "    averages[\"nDCG@10\"] = filtered_df[\"nDCG@10\"].mean()\n",
    "    averages[\"MAP\"] = filtered_df[\"MAP\"].mean()\n",
    "    averages[\"MRR\"] = filtered_df[\"MRR\"].mean()\n",
    "    all_averages.append(averages)\n",
    "\n",
    "print(pd.DataFrame(all_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Paraphrase   nDCG@10       MAP  \\\n",
      "0  Improve the search effectiveness by suggesting...  0.247514  0.118850   \n",
      "1  Recommend expansion terms for the query to imp...  0.249153  0.119355   \n",
      "2  Improve the search effectiveness by suggesting...  0.251727  0.119402   \n",
      "3  Maximize search utility by suggesting relevant...  0.247432  0.118499   \n",
      "4  Enhance search efficiency by proposing valuabl...  0.248368  0.119629   \n",
      "5  Elevate search performance by recommending rel...  0.249150  0.118980   \n",
      "6  Boost the search accuracy by providing helpful...  0.247564  0.119698   \n",
      "7  Increase the search efficacy by offering benef...  0.247129  0.119961   \n",
      "8  Optimize search results by suggesting meaningf...  0.248490  0.119679   \n",
      "9  Enhance search outcomes by recommending benefi...  0.249647  0.119387   \n",
      "\n",
      "        MRR  \n",
      "0  0.470852  \n",
      "1  0.465177  \n",
      "2  0.476066  \n",
      "3  0.473483  \n",
      "4  0.473474  \n",
      "5  0.468137  \n",
      "6  0.460090  \n",
      "7  0.469728  \n",
      "8  0.483019  \n",
      "9  0.468652  \n"
     ]
    }
   ],
   "source": [
    "# Avg per paraphrase\n",
    "\n",
    "def filter_condition(subset_num, paraphrase):\n",
    "    if paraphrase in subset_num_to_paraphrases(subset_num):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "all_averages = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    averages = {}\n",
    "    averages[\"Paraphrase\"] = paraphrases[i]\n",
    "    filtered_df = df[df[\"Subset\"].apply(lambda x: filter_condition(x, paraphrases[i]))]\n",
    "    averages[\"nDCG@10\"] = filtered_df[\"nDCG@10\"].mean()\n",
    "    averages[\"MAP\"] = filtered_df[\"MAP\"].mean()\n",
    "    averages[\"MRR\"] = filtered_df[\"MRR\"].mean()\n",
    "    all_averages.append(averages)\n",
    "\n",
    "print(pd.DataFrame(all_averages))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
